{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq: Translation Chatbot with Attention\n",
    "#### アテンションLSTMによる機械翻訳 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/2600/1*1I2tTjCkMHlQ-r73eRn4ZQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoderアーキテクチャ\n",
    "1. Sentence Data を3つのNumpy配列、（encoder_input_data、decoder_input_data、decoder_target_data）に変換.\n",
    "  - encoder_input_dataは、（num_pairs、max_english_sentence_length、num_english_characters）の3D配列. *英語文はOne-Hotベクトル\n",
    "  - decoder_input_dataは、（num_pairs、max_french_sentence_length、num_french_characters）の3D配列. *日本語文はOne-Hotベクトル\n",
    "  - decoder_target_dataは、decoder_input_dataと同じだが、1 Time Step オフセットされている.\n",
    "2. encoder_input_dataとdecoder_input_dataが与えられ、decoder_target_dataを予測するために基本的なLSTMベースのSeq2Seqモデルを訓練する.\n",
    "3. いくつかのサンプル文をデコードして、モデルが機能していることを確認する."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0315_seq2seq_translater.ipynb  seq2seq_translater.ipynb\r\n",
      "jpn.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import pickle\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess feeding data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. 日英会話データをロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"jpn.txt\", 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43954"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.\\t行け。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43953"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "bos = \"<BOS> \"\n",
    "eos = \" <EOS>\"\n",
    "\n",
    "for line in lines:\n",
    "    if len(line.split(\"\\t\")) == 2:\n",
    "        input_text, target_text = line.split(\"\\t\")[0], line.split(\"\\t\")[1]\n",
    "        target_text = bos + target_text + eos\n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "\n",
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43953"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = len(target_texts)\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I had hardly opened my mouth, when she interrupted me.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> まだ私がほとんど何も言わないうちに彼女が割って入った。 <EOS>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. トークン化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37636"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 英語をcharacter単位で分解\n",
    "input_characters = set()\n",
    "\n",
    "for text in input_texts:\n",
    "    char = text.split()\n",
    "    for char in input_texts:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "english_char_size = len(input_characters)\n",
    "english_char_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 日本語をcharacter単位で分解\n",
    "target_characters = set()\n",
    "\n",
    "for text in target_texts:\n",
    "    char = text.split()\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "target_characters = sorted(list(target_characters))\n",
    "japanese_char_size = len(target_characters)\n",
    "japanese_char_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大文章の長さをえる\n",
    "english_maxlen = max([ len(text) for text in input_texts ])\n",
    "japanese_maxlen = max([ len(text) for text in target_texts ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. ベクトル化&辞書作り"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_char_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index_char = dict(\n",
    "    (i, char) for char, i in input_char_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_index_char = dict(\n",
    "    (i, char) for char, i in target_char_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3Dテンソル (サンプル数, MAX_LEN, 辞書サイズ)\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), english_maxlen, english_char_size),\n",
    "    dtype=\"float32\")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), japanese_maxlen, japanese_char_size),\n",
    "    dtype=\"float32\")\n",
    "\n",
    "decoder_output_data = np.zeros(\n",
    "    (len(input_texts), japanese_maxlen, japanese_char_size),\n",
    "    dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.', 'Go.', 'Hi.', 'Hi.', 'Run.', 'Run.', 'Who?', 'Wow!', 'Wow!', 'Wow!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'G'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-3d979c690283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mencoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_char_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'G'"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(input_texts):\n",
    "    char = char.lower()\n",
    "    for j, char in enumerate(text):\n",
    "        encoder_input_data[i][j][input_char_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'け'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2dda4559d2e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mdecoder_input_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_char_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# decoderのアウトプットは1ステップずれる\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'け'"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(target_texts):\n",
    "    for j, char in enumerate(text):\n",
    "        decoder_input_data[i][j][target_char_index[char]] = 1.\n",
    "        # decoderのアウトプットは1ステップずれる\n",
    "        if j > 0:\n",
    "            decoder_output_data[i, j-1, target_char_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "1. Encode the input sequence into state vectors.\n",
    "2. Start with a target sequence of size 1 (just the start-of-sequence character).\n",
    "3. Feed the state vectors and 1-char target sequence to the decoder to produce predictions for the next character.\n",
    "4. Sample the next character using these predictions (we simply use argmax).\n",
    "5. Append the sampled character to the target sequence\n",
    "6. Repeat until we generate the end-of-sequence character or we hit the character limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoder入力データ: id化された単語シーケンス（英語）\n",
    "- Encoder入力層: None×単語シーケンスの長さの2次元マトリックス\n",
    "- EncoderのLSTM層: 指定の隠れ層のユニット数\n",
    "- Decoder入力データ: id化された単語シーケンス（日本語）\n",
    "- Decoder入力層: None×単語シーケンスの長さの2次元マトリックス\n",
    "- DecoderのLSTM層: 指定の隠れ層のユニット数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "NUM_ENCODER_TOKENS = english_char_size\n",
    "NUM_DECODER_TOKENS = japanese_char_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, NUM_ENCODER_TOKENS))\n",
    "encoder_LSTM = LSTM(units=HIDDEN_DIM, return_state=True) # this is the key\n",
    "encoder_outputs, state_h, state_c = encoder_LSTM(encoder_inputs) # encoderの出力は無視する、memory cellの状態だけ保存\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, NUM_DECODER_TOKENS))\n",
    "decoder_LSTM = LSTM(units=HIDDEN_DIM, return_sequences=True, return_state=True) # this is the key\n",
    "decoder_outputs, _h, _c = decoder_LSTM(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(units=NUM_DECODER_TOKENS, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file = \"seq2seq_translation.png\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Layer works as encoder and decoder\n",
    "- Encoder: 入力シーケンスを処理し、それ自体の内部状態を返す.この内部状態は、次のステップでDecoderの「文脈」と「状態」として機能する.\n",
    "- Decoder: 1つ前の文字があれば、ターゲットシーケンスの次の文字を予測するように訓練されている. \n",
    "- Thought Vector: Encoderは初期状態としてEncoderからの状態ベクトルを使用. これはDecoderが生成するものに関する情報を取得するメソッド."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- return_stateコンストラクタ引数。\n",
    "- 最初のエントリが出力で次のエントリが内部RNN状態であるリストを返すようにRNNレイヤを設定します。\n",
    "- これはエンコーダの状態を回復するために使用されます。\n",
    "- RNNの初期状態を指定するinital_state呼び出し引数。\n",
    "- これは、初期状態としてエンコーダ状態をデコーダに渡すために使用されます。\n",
    "- return_sequencesコンストラクター引数。\n",
    "- RNNがその完全な出力シーケンスを返すように設定します（デフォルトの動作である最後の出力だけではなく）。\n",
    "- これはデコーダで使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fitting and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2)\n",
    "\n",
    "model.save(\"seq2seq_translation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = [32, 64]\n",
    "EPOCHS = [5, 10]\n",
    "\n",
    "for i in range(2):\n",
    "    BATCH_SIZE = BATCH_SIZE[i]\n",
    "    for e in range(2):\n",
    "        EPOCHS = EPOCHS[e]\n",
    "        print(\"------------------------------------\")\n",
    "        print(\"BATCH_SIZE: \", BATCH_SIZE)\n",
    "        print(\"EPOCHS: \", EPOCHS)\n",
    "        history = model.fit([encoder_input_data, decoder_input_data], decoder_output_data,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            epochs=EPOCHS,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(HIDDEN_DIM,))\n",
    "decoder_state_input_c = Input(shape=(HIDDEN_DIM,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, _h, _c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [_h, _c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_translater(english_input):\n",
    "    \n",
    "    encoder_states = encoder_model.predict(english_input)\n",
    "\n",
    "    japanese_seq = np.zeros((1, 1, NUM_DECODER_TOKENS))\n",
    "    japanese_seq[0, 0, target_char_index[bos]] = 1.\n",
    "    \n",
    "    stop_condition = False\n",
    "    japanese_output = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([japanese_seq] + encoder_states)\n",
    "        # ソフトマックスが最大のcharのidを返す np.argmax\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        # 日本語の単語に変換\n",
    "        sampled_char = target_index_char[sampled_token_index]\n",
    "        japanese_output += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        if (sampled_char == eos or len(japanese_output) > japanese_maxlen):\n",
    "            stop_condition = True\n",
    "\n",
    "        japanese_seq = np.zeros((1, 1, NUM_DECODER_TOKENS))\n",
    "        japanese_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        encoder_states = [_h, _c]\n",
    "\n",
    "    return japanese_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text = \"I am so tired and I feel bored to go back to my home.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_translater(english_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
