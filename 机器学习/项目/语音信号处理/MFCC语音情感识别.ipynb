{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adv_statistics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#still working...\n",
    "#different statistics over low level features\n",
    "def negentropy(A):\n",
    "\tne = []\n",
    "\tfor u in A:\n",
    "\t\ta1 = 2\n",
    "\t\tG1 = 1/a1*np.log(np.cosh(2*u))#np.cosh是双曲余弦函数，我不清楚它这个代码是什么目的\n",
    "\t\tv = np.random.normal(0, 1, len(u))#生成u长度的服从标准正态分布的随机数\n",
    "\t\tG2 = -np.exp(-np.power(v,2)/2)\n",
    "\t\tne.append(np.power(np.mean(G1)-np.mean(G2),2))\n",
    "\treturn np.array(ne)\n",
    "\n",
    "#good for discrete features\n",
    "def differences_entropy(A):\n",
    "\tdH = []\n",
    "\tfor f in A:\n",
    "\t\tY = np.diff(f)#后一个减去前一个\n",
    "\t\tP = []\n",
    "\t\tfor yk in Y:\n",
    "\t\t\tntimes = Y.tolist().count(yk)\n",
    "\t\t\tP.append(ntimes/len(Y))#最终P有个屁用？\n",
    "\t\tdH.append(entropy(Y)/np.log(len(Y)))\n",
    "\treturn np.array(dH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioBasicIO\n",
    "import os\n",
    "import subprocess as sp\n",
    "import itertools\n",
    "\n",
    "class Dataset:\n",
    "\n",
    "\t# Dataset object is composed of:\n",
    "\t# data \n",
    "\t# targets\n",
    "\t# train and test sets for cross validation\n",
    "\t# classes dictionary to map classes to numbers\n",
    "\n",
    "\tdef __init__(self,path,decode):\n",
    "        self.classes = {0:'W', 1:'L', 2:'E', 3:'A', 4:'F', 5:'T', 6:'N'}\n",
    "        self.get_berlin_dataset(path)\n",
    "\n",
    "\tdef get_berlin_dataset(self,path):\n",
    "\t\tmales = ['03','10','11','12','15']\n",
    "\t\tfemales = ['08','09','13','14','16']\n",
    "\t\tclasses = {v: k for k, v in self.classes.iteritems()}\n",
    "\t\tself.targets = []; self.data = []; self.train_sets = []; self.test_sets = []; get_data = True\n",
    "\t\tfor speak_test in itertools.product(males,females):#test_couples:\n",
    "\t\t\ti = 0; train = []; test = [];\n",
    "\t\t\tfor audio in os.listdir(path):\n",
    "\t\t\t\taudio_path = os.path.join(path,audio)\n",
    "\t\t\t\t[Fs,x] = audioBasicIO.readAudioFile(audio_path)\n",
    "\t\t\t\tif get_data:\n",
    "\t\t\t\t\tself.data.append((x,Fs))\n",
    "\t\t\t\t\tself.targets.append(classes[audio[5]])\n",
    "\t\t\t\tif audio[:2] in speak_test:\n",
    "\t\t\t\t\ttest.append(i)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttrain.append(i)\n",
    "\t\t\t\ti = i + 1\n",
    "\t\t\tself.train_sets.append(train)\n",
    "\t\t\tself.test_sets.append(test)\n",
    "\t\t\tget_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.linalg import eigh\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "class Eigenspectrum:\n",
    "\n",
    "\t# Eigenspectrum is composed of:\n",
    "\t# eigenvalues\n",
    "\t# % info for each eigenvalue\n",
    "\t# you can plot it using show()\n",
    "\n",
    "\tdef __init__(self, F):\n",
    "\t\tself.eigenvalues = eigh(np.cov(F.T),eigvals_only=True)\n",
    "\t\ttotal_inf = np.sum(self.eigenvalues)\n",
    "\t\tself.info = self.eigenvalues/total_inf*100\n",
    "\n",
    "\tdef show(self):\n",
    "\t\tinfo = self.info[::-1]\n",
    "\t\tplt.plot(range(0,len(self.eigenvalues)),info)\n",
    "\t\tplt.title('Eigenspectrum')\n",
    "\t\tplt.show()\n",
    "\n",
    "class Preprocessor:\n",
    "\n",
    "\t# Preprocessor is composed of:\n",
    "\t# scaler (minmax or standard)\n",
    "\t# a pc projector\n",
    "\t# you can also remove features using mutual_info_select()\n",
    "\n",
    "\tdef __init__(self,scaler_type,n_components):\n",
    "\t\tif scaler_type == \"standard\":\n",
    "\t\t\tself.scaler = StandardScaler()\n",
    "\t\telif scaler_type == \"minmax\":\n",
    "\t\t\tself.scaler = MinMaxScaler()\n",
    "\t\tself.pca = PCA(n_components)\n",
    "\n",
    "\tdef standardize(self,Ftrain,Ftest):\n",
    "\t\tFtrain_std = self.scaler.fit_transform(Ftrain)\n",
    "\t\tFtest_std = self.scaler.transform(Ftest)\n",
    "\t\treturn (Ftrain_std,Ftest_std)\n",
    "\n",
    "\tdef project_on_pc(self,Ftrain,Ftest):\n",
    "\t\tFtrain_pca = self.pca.fit_transform(Ftrain)\n",
    "\t\tFtest_pca = self.pca.transform(Ftest)\n",
    "\t\treturn (Ftrain_pca,Ftest_pca)\n",
    "\n",
    "\tdef mutual_info_select(self,F,y,threshold):\n",
    "\t\tmi = list(enumerate(mutual_info_classif(F,y)))\n",
    "\t\tf_best = []\n",
    "\t\tfor (ind,rank) in mi:\n",
    "\t\t\tif rank > threshold:\n",
    "\t\t\t\tf_best.append(ind)\n",
    "\t\treturn f_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## emorecognition.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioFeatureExtraction\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from scipy.stats import entropy\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import cPickle\n",
    "from time import sleep\n",
    "import sys\n",
    "from dataset import Dataset\n",
    "from preprocessing import Eigenspectrum, Preprocessor\n",
    "#from adv_statistics import negentropy, differences_entropy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t#warnings.filterwarnings('ignore')\n",
    "\tparser = ArgumentParser()\n",
    "\tparser.add_augument(\"-d\", \"--dataset\", dest=\"db_type\", default=\"berlin\")\n",
    "\tparser.add_augument(\"-p\", \"--dataset_path\", dest=\"path\", default=\"\")\n",
    "\tparser.add_augument(\"-l\", \"--load_data\", action=\"store_true\", dest=\"load_data\")\n",
    "\tparser.add_augument(\"-e\", \"--extract_features\", action=\"store_true\", dest=\"extract_features\")\n",
    "\tparser.add_augument(\"-s\", \"--speaker_indipendence\", action=\"store_true\", dest=\"speaker_indipendence\")\n",
    "\tparser.add_augument(\"-i\", \"--plot_eigenspectrum\", action=\"store_true\", dest=\"plot_eigenspectrum\")\n",
    "\t(options, args) = parser.parse_args(sys.argv)\n",
    "\tload_data = options.load_data\n",
    "\textract_features = options.extract_features\n",
    "\tdb_type = options.db_type\n",
    "\tspeaker_indipendence = options.speaker_indipendence\n",
    "\tpath = options.path\n",
    "\tplot_eigenspectrum = options.plot_eigenspectrum\n",
    "\n",
    "\tif load_data:\n",
    "\t\tprint(\"Loading data from \" + db_type + \" dataset...\")\n",
    "\t\tif db_type not in ('berlin'):\n",
    "\t\t\tsys.exit(\"Dataset not registered. Please create a method to read it\")\n",
    "\n",
    "\t\tdb = Dataset(path,decode=False)\n",
    "\n",
    "\t\tprint(\"Saving \" + db_type + \" dataset info to file...\")\n",
    "\t\tcPickle.dump(db, open(db_type + '_db.p', 'wb')) \n",
    "\telse:\n",
    "\t\tprint \"Getting data from \" + db_type + \" dataset...\"\n",
    "\t\tdb = cPickle.load(open(db_type + '_db.p', 'rb'))\n",
    "\n",
    "\tn_samples = len(db.targets)\n",
    "\tprint \"Number of dataset samples: \" + str(n_samples)\n",
    "\n",
    "\tif extract_features:\n",
    "\t\twin_size = 0.04\n",
    "\t\tstep = 0.01\n",
    "\t\tFglobal = []\n",
    "\t\ti = 0\n",
    "\t\tfor (x,Fs) in db.data:\n",
    "\t\t\tF = audioFeatureExtraction.stFeatureExtraction(x, Fs, win_size*Fs, step*Fs)\n",
    "\t\t\tFglobal.append( np.concatenate((\tnp.mean(F, axis=1),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnp.std(F, axis=1))))\n",
    "\n",
    "\t\t\tsys.stdout.write(\"\\033[F\") # cursor up one line\n",
    "\t\t\ti = i+1; print \"Extracting features \" + str(i) + '/' + str(n_samples) + \" from data...\"\n",
    "\n",
    "\t\tprint \"Saving features to file...\"\n",
    "\t\tcPickle.dump(Fglobal, open(db_type + '_features.p', 'wb')) \n",
    "\telse:\n",
    "\t\tprint \"Getting features from files...\"\n",
    "\t\tFglobal = cPickle.load(open(db_type + '_features.p', 'rb'))\n",
    "\n",
    "\tFglobal = np.array(Fglobal)\n",
    "\ty = np.array(db.targets)\n",
    "\n",
    "\t# evaluating SVM using cross validation\n",
    "\tprint \"Evaluating model with cross validation...\"\n",
    "\n",
    "\tif speaker_indipendence:\n",
    "\t\tk_folds = len(db.test_sets)\n",
    "\t\tsplits = zip(db.train_sets,db.test_sets)\n",
    "\telse:\n",
    "\t\tk_folds = 10\n",
    "\t\tsss = StratifiedShuffleSplit(n_splits=k_folds, test_size=0.2, random_state=1)\n",
    "\t\tsplits = sss.split(Fglobal, y)\n",
    "\n",
    "\t# setting preprocessing\n",
    "\tpp = Preprocessor('standard',n_components=50)\n",
    "\tn_classes = len(db.classes)\n",
    "\tclf = OneVsRestClassifier(svm.SVC(kernel='rbf',C=10, gamma=0.01))\n",
    "\tprfs = []; scores = []; acc = np.zeros(n_classes)\n",
    "\tmi_threshold = 0.0\n",
    "\tfor (train,test) in splits:\n",
    "\t\t# selecting features using mutual information\n",
    "\t\tFtrain = Fglobal[train]; Ftest = Fglobal[test]\n",
    "\t\tf_subset = pp.mutual_info_select(Ftrain,y[train],mi_threshold)\n",
    "\t\tFtrain = Ftrain[:,f_subset]; Ftest = Ftest[:,f_subset]\n",
    "\t\t\n",
    "\t\t#standard transformation\n",
    "\t\t(Ftrain,Ftest) = pp.standardize(Ftrain,Ftest)\n",
    "\t\t\n",
    "\t\t# eigenspectrum over all data\n",
    "\t\tif plot_eigenspectrum:\n",
    "\t\t\tes = Eigenspectrum(Ftrain)\n",
    "\t\t\tes.show()\n",
    "\t\t\n",
    "\t\t(Ftrain,Ftest) = pp.project_on_pc(Ftrain,Ftest)\n",
    "\n",
    "\t\tclf.fit(Ftrain, y[train])\n",
    "\t\typred = clf.predict(Ftest)\n",
    "\n",
    "\t\t#print clf.score(Ftest, y[test])\n",
    "\t\tscores.append(clf.score(Ftest, y[test]))\n",
    "\t\t#print precision_recall_fscore_support(y[test], ypred)\n",
    "\t\tprfs.append(precision_recall_fscore_support(y[test], ypred))\n",
    "\n",
    "\t# mean total accuracy\n",
    "\tprint(\"\\nAccuracy =  %0.2f (%0.2f)\\n\" % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "\t#mean per class precision and recall \n",
    "\tmean_prec = np.zeros((1,n_classes))\n",
    "\tmean_recall = np.zeros((1,n_classes))\n",
    "\tprecs = []; recalls = []\n",
    "\tfor mat in prfs:\n",
    "\t\tprecs.append(mat[0])\n",
    "\t\trecalls.append(mat[1])\n",
    "\t\tmean_prec = mean_prec + mat[0]\n",
    "\t\tmean_recall = mean_recall + mat[1]\n",
    "\tmean_prec = mean_prec[0] / k_folds\n",
    "\tmean_recall = mean_recall[0] / k_folds\n",
    "\n",
    "\t#mean total recall and precision\n",
    "\tprecs = np.array(precs)\n",
    "\trecalls = np.array(recalls)\n",
    "\tprec_mean = np.mean(precs,axis=0)\n",
    "\tprec_std = np.std(precs,axis=0)\n",
    "\trecall_mean = np.mean(recalls,axis=0)\n",
    "\trecall_std = np.std(recalls,axis=0)\n",
    "\tprint \"Recall %0.2f (%0.2f)\" % (np.mean(recall_mean), np.std(recall_mean))\n",
    "\tprint \"Precision: %0.2f (%0.2f)\\n\" % (np.mean(prec_mean), np.std(prec_mean))\n",
    "\n",
    "\tfor i in range(0,n_classes):\n",
    "\t\tprint db.classes[i] + \" precision = %0.2f (%0.2f)\" % (prec_mean[i],prec_std[i])\n",
    "\t\tprint db.classes[i] + \" recall = %0.2f (%0.2f)\\n\" % (recall_mean[i],recall_std[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
